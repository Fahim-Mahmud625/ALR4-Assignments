---
title: "Assignment 3"
author: "Ishtiaq Mahmud Fahim"
format: pdf
editor: visual
---

# 5.1 Solution

## 5.1.1

If **X** is at its lowest level , $\pmb{\text{U}}_2 = ...= \pmb{\text{U}}_d = 0$

$$
\mathbb{E}[Y|U_2=0,...,U_j=0] = \beta_0
$$

If **X** is at level j, $\pmb{\text{U}}_j = 1 \space \text{for any j} \in \text{{2,...,d}}$

$$
\mathbb{E}[Y|U_j=1,U_k=0,k \not= j] = \beta_0 + \beta_d
$$

## 5.1.2

For fixed j,

$$
RSS(\beta) = \sum_{j=1}^{d} \sum_{i=1}^{n_j} (y_{ji} - \mu_j)^2
$$

Since the least squares estimate of a population mean is the sample mean, setting the derivative of **RSS** and setting it equals to 0 gives us,

$$
\begin{aligned}
&\hat{\beta_0} = \hat{\mu_1} = \bar{y_1} \\
&\hat{\beta_j} = \hat{\mu_j} - \hat{\mu_1} = \bar{y_j} - \bar{y_1} \qquad \forall  j > 1 
\end{aligned}
$$

\newpage

## 5.1.3

Evaluating the RSS function at OLS estimates,

$$
\begin{aligned}
RSS(\hat{\beta}) &= \sum_{j=1}^{d} \sum_{i=1}^{n_j} (y_{ji} - \hat{\mu}_j)^2 \\
&= \sum_{j=1}^{d} \left[\sum_{i=1}^{n_j} (y_{ji} - \hat{\mu}_j)^2 \right] \\
&= \sum_{j=1}^{d} (n_j - 1) SD_j^2
\end{aligned}
$$

The degrees of freedom for **RSS** is (n-d).

## 5.1.4

For equal $\text{n}_\text{j}$ , let $\text{n}_\text{j} = \text{n}_\text{1}$, the standard errors follow:

$$
se(\hat{\beta}_0|U)^2 = se(\hat{\mu}_1|U)^2 = \frac{\sigma^2}{n_1}
$$

Now,

$$
\begin{aligned}
se(\hat{\beta}_j|U)^2 &= se(\hat{\mu}_j - \hat{\mu}_1|U)^2 \\
&= se(\hat{\mu}_j|U)^2 + se(\hat{\mu}_1|U)^2 \\
&= \frac{\sigma^2}{n_1} + \frac{\sigma^2}{n_1} \\
&=  se(\hat{\beta}_0|U)^2 + se(\hat{\beta}_0|U)^2
\end{aligned}
$$

Thus, the statement is satisfied.

\newpage

# 5.4 Solution

```{r  message=FALSE, warning=FALSE}

library(tidyverse)
library(alr4)
```

As our main focus will be **acrePrice** and **year** we can trim the data set for our flexibility.

```{r}

dat <- MinnLand %>%
  mutate(`log(acrePrice)` = log(acrePrice), year = as.factor(year)) %>% 
  select(acrePrice,`log(acrePrice)`,year) %>% 
  arrange(year) 

head(dat)
```

\newpage

## 5.4.1

```{r}

ggplot(dat) +
  geom_boxplot(
    aes(
      x = year,
      y = `log(acrePrice)`,
      fill = year
    )
  )
```

From the boxplot it can be said that the pattern stated in the question did not repeat here.

\newpage

## 5.4.2

```{r}

ml_reg <- function(data,response,predictors){
  
  dat<- data %>%
    mutate(intercept=1) %>%
    select(intercept,predictors)
  
  X= as.matrix(dat)
  
  response = data %>% select(response)
  Y= as.matrix(response)
  Beta<- solve( (t(X) %*% X) ) %*% t(X) %*% Y
  Y_hat<- X%*%Beta
  residuals<- Y - Y_hat
  RSS<- sum(residuals^2)
  n = nrow(data)
  p = nrow(Beta) - 1
  sigma_2= RSS/(n-p+1)
  var_est= sigma_2 * solve(t(X) %*% X)
  se_Beta= sqrt(diag(var_est))
  t_values = Beta/ se_Beta
  p_values = 2 * pt(abs(t_values),(n-p+1),lower.tail = FALSE)
  pv = if_else(p_values >= 0.001, as.character(round(p_values,3)), "< 0.001")
  
  return(list(
    beta = setNames(as.vector(Beta), colnames(X)),
    se_beta = setNames(as.vector(se_Beta), colnames(X)),
    t_values = setNames(as.vector(t_values), colnames(X)),
    p_val = setNames(as.vector(pv), colnames(X))
  ))
}

```

\newpage

Adding dummy variable,

```{r}

dat <- dat %>% 
  mutate(
    U1 = if_else(year == "2002", 1, 0),
    U2 = if_else(year == "2003", 1, 0),
    U3 = if_else(year == "2004", 1, 0),
    U4 = if_else(year == "2005", 1, 0),
    U5 = if_else(year == "2006", 1, 0),
    U6 = if_else(year == "2007", 1, 0),
    U7 = if_else(year == "2008", 1, 0),
    U8 = if_else(year == "2009", 1, 0),
    U9 = if_else(year == "2010", 1, 0),
    U10 = if_else(year == "2011", 1, 0)
  )

```

```{r}
head(dat,3)
```

```{r}
tail(dat,3)
```

\newpage

Now using our previously written function, we can get or desired estimates,

```{r message=FALSE, warning=FALSE}

predictors <- c("U2","U3","U4","U5","U6","U7","U8","U9","U10")
data.frame(ml_reg(dat,"log(acrePrice)",predictors))

```

All coefficient other than **U2** seems to be significant.

\newpage

## 5.4.3

```{r}

ml_reg_omit <- function(data,response,predictors){
  
  dat<- data %>%
    select(predictors)
  
  X= as.matrix(dat)
  
  response = data %>% select(response)
  Y= as.matrix(response)
  Beta<- solve( (t(X) %*% X) ) %*% t(X) %*% Y
  Y_hat<- X%*%Beta
  residuals<- Y - Y_hat
  RSS<- sum(residuals^2)
  n = nrow(data)
  p = nrow(Beta) - 1
  sigma_2= RSS/(n-p+1)
  var_est= sigma_2 * solve(t(X) %*% X)
  se_Beta= sqrt(diag(var_est))
  t_values = Beta/ se_Beta
  p_values = 2 * pt(abs(t_values),(n-p+1),lower.tail = FALSE)
  pv = if_else(p_values >= 0.001, as.character(round(p_values,3)), "< 0.001")
  
  return(list(
    beta = setNames(as.vector(Beta), colnames(X)),
    se_beta = setNames(as.vector(se_Beta), colnames(X)),
    t_values = setNames(as.vector(t_values), colnames(X)),
    p_val = setNames(as.vector(pv), colnames(X))
  ))
}

```

\newpage

```{r message=FALSE,warning=FALSE}

predictors <- c("U1","U2","U3","U4","U5","U6","U7","U8","U9","U10")
ml_omit <- data.frame(ml_reg_omit(dat,"log(acrePrice)",predictors))

mean <- tapply(dat$`log(acrePrice)`, dat$year, mean)

se_mean <- function(x){
  return(sd(x) / sqrt(length(x)))
}

sd_mean <- tapply(dat$`log(acrePrice)`, dat$year, se_mean)

ml_omit %>% 
  mutate(
    mean = mean,
    se = sd_mean
  ) %>% 
  select(
    beta,mean,se_beta,se
  )

```

After omitting the intercept, it can be seen that the parameter estimates are indeed the mean of **log(acrePrice)** for every year. Also the standard error of the coefficients differ from that of standard error of the mean. The difference arises because regression accounts for residual variance across all years, while the mean based standard errors only consider within year variability.
